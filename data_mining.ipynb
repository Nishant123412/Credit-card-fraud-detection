{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction_df = pd.read_csv('/Users/mayurdeo/Downloads/ieee-fraud-detection/train_transaction.csv')\n",
    "train_identity_df = pd.read_csv('/Users/mayurdeo/Downloads/ieee-fraud-detection/train_identity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROSSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_transaction_df.merge(train_identity_df, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo',\n",
    "] + [f'M{n}' for n in range(1, 10)] + [f'id_{n}' for n in range(12, 39)]\n",
    "num_cols = list(set(df_train.columns) - set(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_train[num_cols].isnull().any() ##getting the columns with NAN\n",
    "train_null_num_cols = a[a].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas = {}              ####Replacing the nans with the median of the column\n",
    "for n in train_null_num_cols:\n",
    "    df_train[f'{n}_isna'] = df_train[n].isnull()\n",
    "    median = df_train[n].median()\n",
    "    df_train[n].fillna(median, inplace=True)\n",
    "    nas[n] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_cols = []\n",
    "for c in num_cols:\n",
    "    try:\n",
    "        if df_train[c].fillna(-1.0).apply(float.is_integer).all():\n",
    "            integer_cols += [c]\n",
    "    except Exception as e:\n",
    "        print(\"error: \", c, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df_train[integer_cols].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Reducing Memory Complexity\n",
    "int8columns = stats[stats['max'] < 256].index\n",
    "int16columns = stats[(stats['max'] >= 256) & (stats['max'] <= 32767)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in int8columns:\n",
    "    df_train[c] = df_train[c].astype('int8')\n",
    "    \n",
    "for c in int16columns:\n",
    "    df_train[c] = df_train[c].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction_df = pd.read_csv('/Users/mayurdeo/Downloads/ieee-fraud-detection/test_transaction.csv')  ####inputing test data\n",
    "test_identity_df = pd.read_csv('/Users/mayurdeo/Downloads/ieee-fraud-detection/test_identity.csv')\n",
    "df_test = test_transaction_df.merge(test_identity_df, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in nas.items():\n",
    "    df_test[f'{k}_isna'] = df_test[k].isnull()\n",
    "    df_test[k].fillna(v, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_cols = list(set(num_cols) - set(['isFraud']))\n",
    "a = df_test[test_num_cols].isnull().any()\n",
    "test_null_num_cols = a[a].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in test_null_num_cols:\n",
    "    df_test[n].fillna(df_train[n].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_cols = []                ####Reducing memory complexity\n",
    "for c in test_num_cols:\n",
    "    try:\n",
    "        if df_test[c].fillna(-1.0).apply(float.is_integer).all():\n",
    "            integer_cols += [c]\n",
    "    except Exception as e:\n",
    "        print(\"error: \", c, e)\n",
    "stats = df_test[integer_cols].describe().transpose()\n",
    "int8columns = stats[stats['max'] < 256].index\n",
    "int16columns = stats[(stats['max'] >= 256) & (stats['max'] <= 32767)].index\n",
    "for c in int8columns:\n",
    "    df_test[c] = df_test[c].astype('int8')\n",
    "    \n",
    "for c in int16columns:\n",
    "    df_test[c] = df_test[c].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorical Variables\n",
    "##we have columns with very high cardinality -- and since we have a large dataset, it's probably more practical to use label encoding which we'll do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols: ##filling nan points with missing\n",
    "    df_train[c] = df_train[c].fillna(\"missing\")\n",
    "    \n",
    "for c in cat_cols:   \n",
    "    df_test[c] = df_test[c].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {}\n",
    "for c in cat_cols:\n",
    "    df_train[c] = df_train[c].astype(\"category\")\n",
    "    df_train[c].cat.add_categories('unknown', inplace=True)\n",
    "    cats[c] = df_train[c].cat.categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cats.items():\n",
    "    df_test[k][~df_test[k].isin(v)] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "for k, v in cats.items():\n",
    "    new_dtype = CategoricalDtype(categories=v, ordered=True)\n",
    "    df_test[k] = df_test[k].astype(new_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    df_train[c] = df_train[c].cat.codes\n",
    "    df_test[c] = df_test[c].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(len(df_train) * 0.8)\n",
    "training_set, validation_set = df_train[:idx], df_train[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training_set['isFraud']\n",
    "X_train = training_set.drop('isFraud', axis=1)\n",
    "y_valid = validation_set['isFraud']\n",
    "X_valid = validation_set.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample = training_set[-100000:]\n",
    "y_train_sample = training_sample['isFraud']\n",
    "X_train_sample = training_sample.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOMFOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=400, max_features=0.3,\n",
    "    min_samples_leaf=20, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, preds_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "modellr = LogisticRegression(random_state = 0,solver='lbfgs') \n",
    "modellr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = model.predict(X_valid)\n",
    "roc_auc_score(y_valid, preds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],axis=0)\n",
    "\n",
    "# create a dataframe\n",
    "importances_df = pd.DataFrame({'variable':X_train.columns, 'importance': importances})\n",
    "\n",
    "top_N = importances_df.sort_values(by=['importance'], ascending=False).head(N)\n",
    "\n",
    "sns.barplot(data = top_N, y = \"variable\", x = \"importance\", palette = 'GnBu_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(decision_function_shape='ovo', gamma='auto')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],axis=0)\n",
    "\n",
    "# create a dataframe\n",
    "importances_df = pd.DataFrame({'variable':X_train.columns, 'importance': importances})\n",
    "\n",
    "top_N = importances_df.sort_values(by=['importance'], ascending=False).head(N)\n",
    "\n",
    "sns.barplot(data = top_N, y = \"variable\", x = \"importance\", palette = 'GnBu_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
